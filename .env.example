# ==============================================
# Urban RL Explainer - Environment Configuration
# ==============================================

# ============= LLM PROVIDER CONFIGURATION =============
# Required: API key for your LLM provider
OPENAI_API_KEY=your_api_key_here

# Required: Base URL for the LLM API endpoint  
OPENAI_BASE_URL=https://api.openai.com/v1

# Required: Model name/identifier
OPENAI_MODEL=gpt-4

# ============= PROVIDER-SPECIFIC EXAMPLES =============

# ---- OpenAI ----
# OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
# OPENAI_BASE_URL=https://api.openai.com/v1
# OPENAI_MODEL=gpt-4o

# ---- Azure OpenAI ----
# OPENAI_API_KEY=your_azure_key_here
# OPENAI_BASE_URL=https://your-resource-name.openai.azure.com/openai/deployments/your-deployment-id
# OPENAI_MODEL=gpt-4o

# ---- Anthropic Claude (via OpenAI-compatible proxy) ----
# OPENAI_API_KEY=your_anthropic_key_here
# OPENAI_BASE_URL=https://api.anthropic.com/v1
# OPENAI_MODEL=claude-3-opus-20240229

# ---- AWS Bedrock (via OpenAI-compatible proxy) ----
# OPENAI_API_KEY=your_aws_access_key
# OPENAI_BASE_URL=https://bedrock-runtime.us-west-2.amazonaws.com/openai/v1
# OPENAI_MODEL=openai.gpt-oss-20b-1:0

# ---- Google AI Studio (via OpenAI-compatible proxy) ----
# OPENAI_API_KEY=your_google_api_key
# OPENAI_BASE_URL=https://generativelanguage.googleapis.com/v1beta/openai/
# OPENAI_MODEL=gemini-2.5-flash

# ---- Local LLM Servers ----
# Ollama
# OPENAI_API_KEY=ollama
# OPENAI_BASE_URL=http://localhost:11434/v1
# OPENAI_MODEL=llama3:8b

# LM Studio
# OPENAI_API_KEY=lm-studio
# OPENAI_BASE_URL=http://localhost:1234/v1
# OPENAI_MODEL=mistral-7b-instruct
